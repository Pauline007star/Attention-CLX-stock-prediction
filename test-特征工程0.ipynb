{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Config\n",
    "MARKET_DATA_PATH=\"/mnt/disk2/peiling.chen/Attention-CLX-stock-prediction/601988.SH.csv\"\n",
    "NEWS_DATA_DIR=\"../../resources/data/CSI300news_chunked_summarized_senti\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 7)\n",
      "┌────────────┬───────┬──────┬──────┬──────┬──────────┬──────────┐\n",
      "│ datetime   ┆ close ┆ open ┆ high ┆ low  ┆ volume   ┆ vwap     │\n",
      "│ ---        ┆ ---   ┆ ---  ┆ ---  ┆ ---  ┆ ---      ┆ ---      │\n",
      "│ date       ┆ f64   ┆ f64  ┆ f64  ┆ f64  ┆ f64      ┆ f64      │\n",
      "╞════════════╪═══════╪══════╪══════╪══════╪══════════╪══════════╡\n",
      "│ 2007-01-04 ┆ 5.63  ┆ 5.69 ┆ 5.97 ┆ 5.37 ┆ 7.2813e6 ┆ 0.580231 │\n",
      "│ 2007-01-05 ┆ 5.07  ┆ 5.3  ┆ 5.34 ┆ 5.07 ┆ 7.8673e6 ┆ 0.514837 │\n",
      "│ 2007-01-08 ┆ 5.08  ┆ 4.87 ┆ 5.14 ┆ 4.83 ┆ 5.5658e6 ┆ 0.496564 │\n",
      "│ 2007-01-09 ┆ 5.18  ┆ 5.06 ┆ 5.19 ┆ 4.95 ┆ 4.3345e6 ┆ 0.507175 │\n",
      "│ 2007-01-10 ┆ 5.1   ┆ 5.25 ┆ 5.29 ┆ 5.05 ┆ 3.7212e6 ┆ 0.514682 │\n",
      "└────────────┴───────┴──────┴──────┴──────┴──────────┴──────────┘\n",
      "Columns before transformation: ['datetime', 'close', 'open', 'high', 'low', 'volume', 'vwap']\n",
      "shape: (5, 170)\n",
      "┌────────────┬───────┬──────┬──────┬───┬───────────────────┬────────┬──────────────┬───────────┐\n",
      "│ datetime   ┆ close ┆ open ┆ high ┆ … ┆ BollingerBandDiff ┆ SMA5   ┆ PriceChannel ┆ LABEL0    │\n",
      "│ ---        ┆ ---   ┆ ---  ┆ ---  ┆   ┆ ---               ┆ ---    ┆ ---          ┆ ---       │\n",
      "│ date       ┆ f64   ┆ f64  ┆ f64  ┆   ┆ f64               ┆ f64    ┆ f64          ┆ f64       │\n",
      "╞════════════╪═══════╪══════╪══════╪═══╪═══════════════════╪════════╪══════════════╪═══════════╡\n",
      "│ 2007-01-04 ┆ 5.63  ┆ 5.69 ┆ 5.97 ┆ … ┆ null              ┆ null   ┆ null         ┆ -0.099467 │\n",
      "│ 2007-01-05 ┆ 5.07  ┆ 5.3  ┆ 5.34 ┆ … ┆ null              ┆ null   ┆ null         ┆ 0.001972  │\n",
      "│ 2007-01-08 ┆ 5.08  ┆ 4.87 ┆ 5.14 ┆ … ┆ null              ┆ null   ┆ null         ┆ 0.019685  │\n",
      "│ 2007-01-09 ┆ 5.18  ┆ 5.06 ┆ 5.19 ┆ … ┆ null              ┆ null   ┆ null         ┆ -0.015444 │\n",
      "│ 2007-01-10 ┆ 5.1   ┆ 5.25 ┆ 5.29 ┆ … ┆ null              ┆ -0.112 ┆ null         ┆ -0.033333 │\n",
      "└────────────┴───────┴──────┴──────┴───┴───────────────────┴────────┴──────────────┴───────────┘\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of ['instrument'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1338175/2599085503.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;31m# 转为 pandas DataFrame 后处理\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0mdf_pd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m df_pd = df_pd.assign(\n\u001b[1;32m     56\u001b[0m     \u001b[0mdatetime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_pd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'instrument'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'datetime'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;31m# 保存为 CSV 文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mdf_pd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/mnt/disk2/peiling.chen/finbot/finbot/modules/forecast/alpha158_features.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/myenv/lib/python3.12/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6118\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6119\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\u001b[0m\u001b[0;34mNone of \u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m are in the columns\u001b[0m\u001b[0;34m\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6125\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['instrument'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import sys; sys.path.append(\"../..\")\n",
    "from finutils.models import *\n",
    "from finutils.alpha import *\n",
    "\n",
    "def transform_data(df: pl.DataFrame):\n",
    "    print(\"Columns before transformation:\", df.columns)  # 打印列名检查\n",
    "    df = build_alpha158(df)\n",
    "    df = build_label(df)\n",
    "    return df\n",
    "\n",
    "# 更新 MARKET_DATA_PATH 为实际文件路径\n",
    "MARKET_DATA_PATH = \"/mnt/disk2/peiling.chen/Attention-CLX-stock-prediction/601988.SH.csv\"\n",
    "\n",
    "df = (\n",
    "    pl.read_csv(MARKET_DATA_PATH)\n",
    "    .with_columns([\n",
    "        pl.col(\"trade_date\").cast(pl.Utf8).str.strptime(pl.Date, \"%Y%m%d\").alias(\"datetime\"),\n",
    "        pl.col(\"ts_code\").alias(\"instrument\"),\n",
    "        (pl.col(\"amount\") / (pl.col(\"vol\") + 1e-12)).alias(\"vwap\")\n",
    "    ])\n",
    "    .filter(\n",
    "        (pl.col(\"datetime\") >= pl.date(2007, 1, 4)) &\n",
    "        (pl.col(\"datetime\") <= pl.date(2022, 3, 17))\n",
    "    )\n",
    "    .sort([\"instrument\", \"datetime\"])\n",
    "    .with_columns([\n",
    "        pl.col(\"instrument\").str.slice(2).alias(\"instrument_short\")\n",
    "    ])\n",
    "    .select([\n",
    "        pl.col(\"datetime\"),\n",
    "        pl.col(\"close\"),\n",
    "        pl.col(\"open\"),\n",
    "        pl.col(\"high\"),\n",
    "        pl.col(\"low\"),\n",
    "        pl.col(\"vol\").alias(\"volume\"),  # 确保这里使用的是 pl.col(\"vol\")\n",
    "        pl.col(\"vwap\")\n",
    "    ])\n",
    ")\n",
    "\n",
    "# 打印结果以检查\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# 构造 alpha 因子 + 标签\n",
    "df = transform_data(df)\n",
    "\n",
    "# 打印结果以检查\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# 转为 pandas DataFrame 后处理\n",
    "df_pd = df.to_pandas()\n",
    "df_pd = df_pd.assign(\n",
    "    datetime=pd.to_datetime(df_pd['datetime']),\n",
    ").set_index(['datetime'])\n",
    "\n",
    "# 保存为 CSV 文件\n",
    "df_pd.to_csv('/mnt/disk2/peiling.chen/finbot/finbot/modules/forecast/alpha158_features.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys; sys.path.append(\"../..\")\n",
    "from finutils.alpha import *\n",
    "import os\n",
    "\n",
    "\n",
    "df_news = pd.concat([(pd\n",
    "    .read_json(os.path.join(NEWS_DATA_DIR, filename))\n",
    "    .assign(instrument=filename.split('.')[0],datetime=lambda x: x['date'].dt.date)\n",
    "    )\n",
    "    for filename in os.listdir(NEWS_DATA_DIR)\n",
    "    if filename.endswith(\".json\")\n",
    "], ignore_index=True)\n",
    "\n",
    "df_senti = build_senti_alpha(df_news,method=\"标签众数\")\n",
    "df_senti = (df_senti\n",
    "    .assign(datetime=pd.to_datetime(df_senti['datetime']))\n",
    "    .fillna({'SENTI': 0})\n",
    "    .set_index(['instrument', 'datetime'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 特征拼接\n",
    "df_tot=pd.merge(df_pd, df_senti, left_index=True, right_index=True, how='left')\n",
    "df_tot.fillna({'SENTI':0}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk2/peiling.chen/myenv/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n",
      "/mnt/disk2/peiling.chen/myenv/lib/python3.12/site-packages/statsmodels/stats/outliers_influence.py:197: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Feature           VIF\n",
      "0                const  0.000000e+00\n",
      "1                 open  3.528640e+04\n",
      "2                 high  6.601279e+04\n",
      "3                  low  5.390689e+04\n",
      "4                close  9.007199e+15\n",
      "..                 ...           ...\n",
      "182  BollingerBandDiff  2.585943e+02\n",
      "183               SMA5  1.491450e+02\n",
      "184       PriceChannel  7.753066e+01\n",
      "185             LABEL0  1.084257e+00\n",
      "186              SENTI           NaN\n",
      "\n",
      "[187 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/disk2/peiling.chen/myenv/lib/python3.12/site-packages/statsmodels/regression/linear_model.py:1782: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  return 1 - self.ssr/self.centered_tss\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "\n",
    "# 获取所有特征列，去除 'ts_code' 和 'trade_date'\n",
    "feature_cols = [col for col in df_tot.columns if col not in ['ts_code', 'trade_date']]\n",
    "\n",
    "# 只选择数值型列\n",
    "df_numerical = df_tot[feature_cols].select_dtypes(include=[float, int])\n",
    "\n",
    "# 用中位数填补缺失值\n",
    "df_numerical = df_numerical.apply(lambda col: col.fillna(col.median()))\n",
    "\n",
    "# 检查并去除任何包含 Inf 或 -Inf 的行\n",
    "df_numerical = df_numerical[np.isfinite(df_numerical).all(axis=1)]\n",
    "\n",
    "# 增加常数项\n",
    "X_with_const = add_constant(df_numerical)\n",
    "\n",
    "# 计算每个特征的VIF\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Feature\"] = X_with_const.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(X_with_const.values, i) for i in range(X_with_const.shape[1])]\n",
    "\n",
    "# 输出VIF结果\n",
    "print(vif_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VIF_Range\n",
      "<5       23\n",
      "5-10      7\n",
      ">=10    154\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 定义 VIF 区间\n",
    "bins = [0, 5, 10, np.inf]\n",
    "labels = [\"<5\", \"5-10\", \">=10\"]\n",
    "\n",
    "# 添加 VIF 区间列\n",
    "vif_data[\"VIF_Range\"] = pd.cut(vif_data[\"VIF\"], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# 统计各区间的特征数量\n",
    "vif_summary = vif_data[\"VIF_Range\"].value_counts().sort_index()\n",
    "\n",
    "# 显示结果\n",
    "print(vif_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已保存筛选后的特征至：/mnt/disk2/peiling.chen/finbot/finbot/modules/forecast/filtered_alpha158_features_new.csv\n"
     ]
    }
   ],
   "source": [
    "# 获取 VIF 在 5-10 区间的特征名称（去除常数项）\n",
    "vif_selected_features = vif_data.loc[\n",
    "    (vif_data[\"VIF\"] >= 5) & (vif_data[\"VIF\"] < 10) & (vif_data[\"Feature\"] != \"const\"),\n",
    "    \"Feature\"\n",
    "].tolist()\n",
    "\n",
    "# 让 datetime 成为第一列，其余特征依次排列\n",
    "ordered_cols = [\"datetime\"] + [col for col in vif_selected_features if col != \"datetime\"]\n",
    "df_filtered = df_filtered[ordered_cols]\n",
    "\n",
    "# 保存到指定路径\n",
    "output_path = \"/mnt/disk2/peiling.chen/finbot/finbot/modules/forecast/filtered_alpha158_features_new.csv\"\n",
    "df_filtered.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"已保存筛选后的特征至：{output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已成功保存合并后的数据至：/mnt/disk2/peiling.chen/Attention-CLX-stock-prediction/merged_data.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 alpha 特征数据\n",
    "alpha_path = \"/mnt/disk2/peiling.chen/finbot/finbot/modules/forecast/filtered_alpha158_features_new.csv\"\n",
    "df_alpha = pd.read_csv(alpha_path)\n",
    "df_alpha[\"datetime\"] = pd.to_datetime(df_alpha[\"datetime\"])\n",
    "\n",
    "# 读取 ARIMA 残差数据\n",
    "arima_path = \"/mnt/disk2/peiling.chen/Attention-CLX-stock-prediction/ARIMA_residuals1.csv\"\n",
    "df_arima = pd.read_csv(arima_path)\n",
    "\n",
    "# 将 trade_date 转换为 datetime 格式\n",
    "df_arima[\"trade_date\"] = pd.to_datetime(df_arima[\"trade_date\"])\n",
    "\n",
    "# 重命名第二列为 factor_x\n",
    "df_arima.rename(columns={df_arima.columns[1]: \"factor_x\"}, inplace=True)\n",
    "\n",
    "# 将 trade_date 列重命名为 datetime 以便合并\n",
    "df_arima[\"datetime\"] = df_arima[\"trade_date\"]\n",
    "\n",
    "# 删除原来的 trade_date 列\n",
    "df_arima.drop(columns=[\"trade_date\"], inplace=True)\n",
    "\n",
    "# 合并数据，按 datetime 列合并\n",
    "df_merged = pd.merge(df_alpha, df_arima, on=\"datetime\", how=\"left\")\n",
    "\n",
    "# 保存结果\n",
    "output_path = \"/mnt/disk2/peiling.chen/Attention-CLX-stock-prediction/merged_data.csv\"\n",
    "df_merged.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"已成功保存合并后的数据至：{output_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
